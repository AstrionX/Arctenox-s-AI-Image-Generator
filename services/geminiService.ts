import { GoogleGenAI, Modality } from "@google/genai";
import type { ImageConfig, SafetyCheckResult } from '../types';
import { getFullPrompt } from '../lib/promptBuilder';
import { CustomStylePreset } from "../types";

if (!process.env.API_KEY) {
  throw new Error("API_KEY environment variable not set for Google GenAI");
}
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// --- PROMPT CONSTANTS ---
export const ENHANCE_PROMPT = "Critically analyze this image and enhance its quality. Increase detail, sharpen focus, improve lighting, and fix any minor artifacts without changing the subject, style, or composition.";
export const FACE_FIX_PROMPT = "Analyze the face(s) in this image and correct any artifacts or imperfections. Ensure the eyes, nose, and mouth are anatomically correct and natural-looking. Improve skin texture and facial details while preserving the character's identity and the original art style.";
export const UPSCALE_PROMPT = "Analyze this image and significantly upscale its resolution and detail. Add fine textures, sharpen lines, and enhance clarity to make it look like a 4k high-resolution image, without changing the subject, style, or composition.";
export const REMOVE_WATERMARK_PROMPT = "Analyze this image and intelligently remove any watermarks, text, logos, or other overlayed graphics. Perfectly reconstruct the background behind the removed elements, matching textures, lighting, and colors seamlessly.";
const CHILD_SAFETY_NEGATIVE_PROMPT = "child, baby, infant, toddler, kid, minor";


// --- HELPER FUNCTIONS ---
function handleApiError(err: unknown, defaultMessage: string): string {
    console.error("API Error:", err);
    if (err instanceof Error) {
         try {
             // Some errors are JSON strings in the message property
             const parsedError = JSON.parse(err.message);
             const errorMessage = parsedError?.error?.message;
             const errorStatus = parsedError?.error?.status;

             if (errorStatus === 'RESOURCE_EXHAUSTED') {
                 return 'You have exceeded your API quota. Please check your plan and billing details.';
             }
             if (errorMessage) return String(errorMessage);
         } catch (e) {
             // Not a JSON string, fall through to the original error message
         }
        return err.message; // Return original message if parsing fails
    }
    
    // Fallback for non-Error types
    if (typeof err === 'object' && err !== null && 'message' in err && typeof err.message === 'string') {
        return err.message;
    }

    return defaultMessage;
}

const dataUrlToInlineData = (dataUrl: string) => {
    const parts = dataUrl.split(',');
    const mimeType = parts[0].match(/:(.*?);/)?.[1];
    const base64Data = parts[1];
    if (!mimeType || !base64Data) {
        throw new Error("Invalid data URL for image processing");
    }
    return {
        mimeType,
        data: base64Data,
    };
};

// --- CORE API FUNCTIONS ---
export const generateImagesFromPrompt = async (
    prompt: string, 
    config: ImageConfig, 
    uploadedImage: { data: string; mimeType: string } | null,
    customStyles: CustomStylePreset[]
): Promise<string[]> => {
    try {
        const fullPrompt = getFullPrompt(prompt, config, customStyles);

        // If an image is uploaded, it's an img2img task, which MUST use the Gemini vision model.
        if (uploadedImage) {
            const parts: any[] = [{ text: fullPrompt }];
            const inlineData = dataUrlToInlineData(uploadedImage.data);
            parts.unshift({ inlineData });

            const response = await ai.models.generateContent({
                model: 'gemini-2.5-flash-image-preview', // Force the correct model for this task
                contents: [{ parts }],
                config: {
                    responseModalities: [Modality.IMAGE, Modality.TEXT],
                },
            });

            const imageParts = response.candidates?.[0]?.content?.parts?.filter(part => part.inlineData);
            if (!imageParts || imageParts.length === 0) {
                 throw new Error("No images generated by Gemini Flash. The prompt may have been blocked or the image could not be processed.");
            }
            return imageParts.map(part => `data:${part.inlineData?.mimeType};base64,${part.inlineData?.data}`);
        }

        // If no image, it's a text-to-image task, so use the model selected in the UI.
        if (config.model === 'imagen-4.0-generate-001') {
            // Per user request, the negative prompt field is disabled for Imagen 4.0.
            // The negativePrompt parameter is not supported by this model and was causing errors.
            const response = await ai.models.generateImages({
                model: config.model,
                prompt: fullPrompt,
                config: {
                    numberOfImages: config.numberOfImages,
                    outputMimeType: 'image/jpeg',
                    aspectRatio: config.aspectRatio,
                },
            });
            return response.generatedImages.map(img => `data:image/jpeg;base64,${img.image.imageBytes}`);
        } else { // gemini-2.5-flash-image-preview
            // This model doesn't accept a separate negative prompt parameter.
            const parts: any[] = [{ text: fullPrompt }];
            const response = await ai.models.generateContent({
                model: config.model,
                contents: [{ parts }],
                config: {
                    responseModalities: [Modality.IMAGE, Modality.TEXT],
                },
            });

            const imageParts = response.candidates?.[0]?.content?.parts?.filter(part => part.inlineData);
            if (!imageParts || imageParts.length === 0) {
                 throw new Error("No images generated by Gemini Flash. The prompt may have been blocked.");
            }
            return imageParts.map(part => `data:${part.inlineData?.mimeType};base64,${part.inlineData?.data}`);
        }

    } catch (err) {
        throw new Error(handleApiError(err, 'Failed to generate images.'));
    }
};

export const postProcessImage = async (imageDataUrl: string, processPrompt: string): Promise<string> => {
    try {
        const inlineData = dataUrlToInlineData(imageDataUrl);

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image-preview',
            contents: [{
                parts: [
                    { inlineData },
                    { text: processPrompt },
                ],
            }],
            config: {
                responseModalities: [Modality.IMAGE, Modality.TEXT],
            },
        });
        
        const imagePart = response.candidates?.[0]?.content?.parts?.find(part => part.inlineData);
        if (!imagePart?.inlineData) {
            throw new Error("Image processing failed or was blocked.");
        }
        return `data:${imagePart.inlineData.mimeType};base64,${imagePart.inlineData.data}`;

    } catch (err) {
        throw new Error(handleApiError(err, 'Failed to post-process image.'));
    }
}

export const enhancePromptWithGemini = async (prompt: string): Promise<string> => {
    try {
        const response = await ai.models.generateContent({
            model: "gemini-2.5-flash",
            contents: `Enhance the following user prompt for an AI image generator to make it more vivid, descriptive, and artistic. Do not add any prefixes like "a painting of". Just expand on the core idea. Return only the enhanced prompt. User prompt: "${prompt}"`,
            config: {
                systemInstruction: "You are a creative assistant that expands on user ideas for AI image generation.",
                temperature: 0.8,
                topK: 32,
            }
        });
        return response.text.trim();
    } catch (err) {
        throw new Error(handleApiError(err, 'Failed to enhance prompt.'));
    }
};

export const checkPromptSafety = async (prompt: string): Promise<SafetyCheckResult> => {
    try {
        const response = await ai.models.generateContent({
            model: "gemini-2.5-flash",
            contents: `Analyze the following prompt for an AI image generator to determine if it's likely to violate safety policies (e.g., explicit content, hate speech, violence).
            - If it's safe, respond with 'SAFE'.
            - If it might be problematic, respond with 'WARNING: [brief explanation of the potential issue]'.
            - If it's a WARNING, provide a safer alternative prompt if possible, prefixed with 'SUGGESTION:'.
            Prompt: "${prompt}"`,
            config: {
                systemInstruction: "You are a helpful safety analysis bot for an AI image generator. You are concise and direct.",
                temperature: 0,
            }
        });

        const text = response.text.trim();
        if (text.startsWith('SAFE')) {
            return { isSafe: true, feedback: "Prompt appears safe.", suggestion: "" };
        } else if (text.startsWith('WARNING:')) {
            const parts = text.split('SUGGESTION:');
            const feedback = parts[0].replace('WARNING:', '').trim();
            const suggestion = parts[1] ? parts[1].trim() : "";
            return { isSafe: false, feedback, suggestion };
        } else {
            return { isSafe: true, feedback: "Safety check inconclusive, but prompt seems okay.", suggestion: "" };
        }

    } catch (err) {
        throw new Error(handleApiError(err, 'Failed to check prompt safety.'));
    }
};